{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a38734",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "<li>Pandas is an open-source Python package that is built on top of NumPy used for working with data sets.</li> \n",
    "<li>The name \"Pandas\" has a reference to <b>\"Python Data Analysis\".</b></li>\n",
    "<li>Pandas is considered to be one of the best data-wrangling packages.</li>\n",
    "<li>Pandas offers user-friendly, easy-to-use data structures and analysis tools for analyzing, cleaning, exploring and manipulating data.</li>\n",
    "<li>It also functions well with various other data science Python modules.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79079ab0",
   "metadata": {},
   "source": [
    "# Difference Between NumPy & Pandas\n",
    "\n",
    "![](images/pandas_vs_numpy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ede164",
   "metadata": {},
   "source": [
    "## Why Use Pandas?\n",
    "\n",
    "<li>Pandas is known for its exceptional ability to represent and organize data.</li>\n",
    "<li>The Pandas library was created to be able to work with large datasets faster and more efficiently than any other library.</li>\n",
    "<li>It excels at analyzing huge amounts of data.Pandas allows us to analyze big data and make conclusions based on statistical theories.</li>\n",
    "<li>Pandas can clean messy data sets, and make them readable and relevant.</li>\n",
    "<li>By combining the functionality of Matplotlib and NumPy, Pandas offers users a powerful tool for performing <b>data analytics and visualization.</b></li>\n",
    "<li>Data can be imported to Pandas from a variety of file formats, such as Csv, SQL, Excel, and JSON, among others.</li>\n",
    "<li>Pandas is a versatile and marketable skill set for data analysts and data scientists that can gain the attention of employers.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97011979",
   "metadata": {},
   "source": [
    "## Installation Of Pandas\n",
    "<li>Go to your terminal, open and activate your virtual environment and then use the following commands for installing pandas.</li>\n",
    "\n",
    "<code>\n",
    "    pip install pandas\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699b7dc",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "<li>We need to import pandas if we want to create a pandas dataframe and perform any analysis on them.</li>\n",
    "<li>We can import pandas package using the following command:</li>\n",
    "<code>\n",
    "    import pandas as pd\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68a52ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140b6ef",
   "metadata": {},
   "source": [
    "## How To Create A Pandas DataFrame\n",
    "<li>A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, arranged in a table like structure with rows and columns.</li>\n",
    "<li>We can create a basic pandas dataframe by various methods.</li>\n",
    "<li>Let's discuss some of the methods to create the given dataframes:</li>\n",
    "\n",
    "![](images/dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75cbcf",
   "metadata": {},
   "source": [
    "### 1. From Python Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "401ec313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>ages</th>\n",
       "      <th>addresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ram</td>\n",
       "      <td>30</td>\n",
       "      <td>kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shyam</td>\n",
       "      <td>25</td>\n",
       "      <td>bhaktapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hari</td>\n",
       "      <td>35</td>\n",
       "      <td>lalitpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   names  ages  addresses\n",
       "0    ram    30  kathmandu\n",
       "1  shyam    25  bhaktapur\n",
       "2   hari    35   lalitpur"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict= {\n",
    "    'names': ['ram', 'shyam', 'hari'],\n",
    "    'ages': [30, 25, 35],\n",
    "    'addresses': ['kathmandu', 'bhaktapur', 'lalitpur']\n",
    "}\n",
    "df=pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795c295",
   "metadata": {},
   "source": [
    "### 2. From a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "505aca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ram</td>\n",
       "      <td>30</td>\n",
       "      <td>kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shyam</td>\n",
       "      <td>25</td>\n",
       "      <td>bhaktapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hari</td>\n",
       "      <td>35</td>\n",
       "      <td>lalitpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age    address\n",
       "0    ram   30  kathmandu\n",
       "1  shyam   25  bhaktapur\n",
       "2   hari   35   lalitpur"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_dict=[\n",
    "    {'name': 'ram', 'age': 30, 'address': 'kathmandu'},\n",
    "    {'name': 'shyam', 'age': 25, 'address': 'bhaktapur'},\n",
    "    {'name': 'hari', 'age': 35, 'address': 'lalitpur'}\n",
    "]\n",
    "df=pd.DataFrame(list_of_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d5b64",
   "metadata": {},
   "source": [
    "### 3. From a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac4907ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ram</td>\n",
       "      <td>30</td>\n",
       "      <td>kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shyam</td>\n",
       "      <td>25</td>\n",
       "      <td>bhaktapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hari</td>\n",
       "      <td>35</td>\n",
       "      <td>lalitpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1          2\n",
       "0    ram  30  kathmandu\n",
       "1  shyam  25  bhaktapur\n",
       "2   hari  35   lalitpur"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuple=[\n",
    "    ('ram', 30, 'kathmandu'),\n",
    "    ('shyam', 25, 'bhaktapur'),\n",
    "    ('hari', 35, 'lalitpur')\n",
    "]\n",
    "df=pd.DataFrame(list_of_tuple)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8ee6c",
   "metadata": {},
   "source": [
    "### 4. From list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b87c8374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ram</td>\n",
       "      <td>30</td>\n",
       "      <td>kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shyam</td>\n",
       "      <td>25</td>\n",
       "      <td>bhaktapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hari</td>\n",
       "      <td>35</td>\n",
       "      <td>lalitpur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1          2\n",
       "0    ram  30  kathmandu\n",
       "1  shyam  25  bhaktapur\n",
       "2   hari  35   lalitpur"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists = [\n",
    "    ['ram', 30, 'kathmandu'],\n",
    "    ['shyam', 25, 'bhaktapur'],\n",
    "    ['hari', 35, 'lalitpur']\n",
    "]\n",
    "df=pd.DataFrame(list_of_lists)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a00fa",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "<li>Read 'weather_data.csv' file using csv reader.</li>\n",
    "<li>Store the data inside the csv file into a list of lists.</li>\n",
    "<li>Then create a pandas dataframe using list of list.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f96fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     kfjkdfjskd     Unnamed: 1    Unnamed: 2 Unnamed: 3\n",
      "0   dfuhsdjufio            NaN           NaN        NaN\n",
      "1           day    temperature     windspeed      event\n",
      "2      1/1/2017             32             6       Rain\n",
      "3      1/4/2017  not available             9      Sunny\n",
      "4      1/5/2017             -1  not measured       Snow\n",
      "5      1/6/2017  not available             7   no event\n",
      "6      1/7/2017             32  not measured       Rain\n",
      "7      1/8/2017  not available  not measured      Sunny\n",
      "8      1/9/2017  not available  not measured   no event\n",
      "9     1/10/2017             34             8     Cloudy\n",
      "10    1/11/2017             -4            -1       Snow\n",
      "11    1/12/2017             26            12      Sunny\n",
      "12    1/13/2017             12            12      Rainy\n",
      "13    1/11/2017             -1            12       Snow\n",
      "14    1/14/2017             40            -1      Sunny\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./weather_data - weather_data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8ee4ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dfuhsdjufio', nan, nan, nan], ['day', 'temperature', 'windspeed', 'event'], ['1/1/2017', '32', '6', 'Rain'], ['1/4/2017', 'not available', '9', 'Sunny'], ['1/5/2017', '-1', 'not measured', 'Snow'], ['1/6/2017', 'not available', '7', 'no event'], ['1/7/2017', '32', 'not measured', 'Rain'], ['1/8/2017', 'not available', 'not measured', 'Sunny'], ['1/9/2017', 'not available', 'not measured', 'no event'], ['1/10/2017', '34', '8', 'Cloudy'], ['1/11/2017', '-4', '-1', 'Snow'], ['1/12/2017', '26', '12', 'Sunny'], ['1/13/2017', '12', '12', 'Rainy'], ['1/11/2017', '-1', '12', 'Snow'], ['1/14/2017', '40', '-1', 'Sunny']]\n"
     ]
    }
   ],
   "source": [
    "#Store the data inside the csv file into a list of lists.\n",
    "lists = df.values.tolist()\n",
    "\n",
    "print(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3b89d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0              1             2         3\n",
      "0   dfuhsdjufio            NaN           NaN       NaN\n",
      "1           day    temperature     windspeed     event\n",
      "2      1/1/2017             32             6      Rain\n",
      "3      1/4/2017  not available             9     Sunny\n",
      "4      1/5/2017             -1  not measured      Snow\n",
      "5      1/6/2017  not available             7  no event\n",
      "6      1/7/2017             32  not measured      Rain\n",
      "7      1/8/2017  not available  not measured     Sunny\n",
      "8      1/9/2017  not available  not measured  no event\n",
      "9     1/10/2017             34             8    Cloudy\n",
      "10    1/11/2017             -4            -1      Snow\n",
      "11    1/12/2017             26            12     Sunny\n",
      "12    1/13/2017             12            12     Rainy\n",
      "13    1/11/2017             -1            12      Snow\n",
      "14    1/14/2017             40            -1     Sunny\n"
     ]
    }
   ],
   "source": [
    "# Then create a pandas dataframe using list of list.\n",
    "new_dataframe = pd.DataFrame(lists)\n",
    "\n",
    "print(new_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c9a6a",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>1. Read 'imports-85.data' file using file reader.</li>\n",
    "<li>2. Store the data present inside the file into a list of list.</li>\n",
    "<li>3. Create a pandas dataframe using list of lists.</li>\n",
    "<li>4. For column name, we can use the columns variable given below.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "278362ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3', '?', 'alfa-romero', 'gas', 'std', 'two', 'convertible', 'rwd', 'front', '88.60', '168.80', '64.10', '48.80', '2548', 'dohc', 'four', '130', 'mpfi', '3.47', '2.68', '9.00', '111', '5000', '21', '27', '13495'], ['3', '?', 'alfa-romero', 'gas', 'std', 'two', 'convertible', 'rwd', 'front', '88.60', '168.80', '64.10', '48.80', '2548', 'dohc', 'four', '130', 'mpfi', '3.47', '2.68', '9.00', '111', '5000', '21', '27', '16500'], ['1', '?', 'alfa-romero', 'gas', 'std', 'two', 'hatchback', 'rwd', 'front', '94.50', '171.20', '65.50', '52.40', '2823', 'ohcv', 'six', '152', 'mpfi', '2.68', '3.47', '9.00', '154', '5000', '19', '26', '16500'], ['2', '164', 'audi', 'gas', 'std', 'four', 'sedan', 'fwd', 'front', '99.80', '176.60', '66.20', '54.30', '2337', 'ohc', 'four', '109', 'mpfi', '3.19', '3.40', '10.00', '102', '5500', '24', '30', '13950'], ['2', '164', 'audi', 'gas', 'std', 'four', 'sedan', '4wd', 'front', '99.40', '176.60', '66.40', '54.30', '2824', 'ohc', 'five', '136', 'mpfi', '3.19', '3.40', '8.00', '115', '5500', '18', '22', '17450']]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read 'imports-85.data' file using file reader\n",
    "data = []\n",
    "with open('./imports-85.data', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(line.strip().split(','))\n",
    "\n",
    "# Print the first few lines of data to verify\n",
    "print(data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "884a017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symboling normalized_losses         make fuel_type aspiration  \\\n",
      "0           3                 ?  alfa-romero       gas        std   \n",
      "1           3                 ?  alfa-romero       gas        std   \n",
      "2           1                 ?  alfa-romero       gas        std   \n",
      "3           2               164         audi       gas        std   \n",
      "4           2               164         audi       gas        std   \n",
      "..        ...               ...          ...       ...        ...   \n",
      "200        -1                95        volvo       gas        std   \n",
      "201        -1                95        volvo       gas      turbo   \n",
      "202        -1                95        volvo       gas        std   \n",
      "203        -1                95        volvo    diesel      turbo   \n",
      "204        -1                95        volvo       gas      turbo   \n",
      "\n",
      "    num_of_doors   body_style drive_wheels engine_location wheel_base  ...  \\\n",
      "0            two  convertible          rwd           front      88.60  ...   \n",
      "1            two  convertible          rwd           front      88.60  ...   \n",
      "2            two    hatchback          rwd           front      94.50  ...   \n",
      "3           four        sedan          fwd           front      99.80  ...   \n",
      "4           four        sedan          4wd           front      99.40  ...   \n",
      "..           ...          ...          ...             ...        ...  ...   \n",
      "200         four        sedan          rwd           front     109.10  ...   \n",
      "201         four        sedan          rwd           front     109.10  ...   \n",
      "202         four        sedan          rwd           front     109.10  ...   \n",
      "203         four        sedan          rwd           front     109.10  ...   \n",
      "204         four        sedan          rwd           front     109.10  ...   \n",
      "\n",
      "    engine_size fuel_system  bore stroke compression horsepower peak_rpm  \\\n",
      "0           130        mpfi  3.47   2.68        9.00        111     5000   \n",
      "1           130        mpfi  3.47   2.68        9.00        111     5000   \n",
      "2           152        mpfi  2.68   3.47        9.00        154     5000   \n",
      "3           109        mpfi  3.19   3.40       10.00        102     5500   \n",
      "4           136        mpfi  3.19   3.40        8.00        115     5500   \n",
      "..          ...         ...   ...    ...         ...        ...      ...   \n",
      "200         141        mpfi  3.78   3.15        9.50        114     5400   \n",
      "201         141        mpfi  3.78   3.15        8.70        160     5300   \n",
      "202         173        mpfi  3.58   2.87        8.80        134     5500   \n",
      "203         145         idi  3.01   3.40       23.00        106     4800   \n",
      "204         141        mpfi  3.78   3.15        9.50        114     5400   \n",
      "\n",
      "    city_mpg highway_mpg  price  \n",
      "0         21          27  13495  \n",
      "1         21          27  16500  \n",
      "2         19          26  16500  \n",
      "3         24          30  13950  \n",
      "4         18          22  17450  \n",
      "..       ...         ...    ...  \n",
      "200       23          28  16845  \n",
      "201       19          25  19045  \n",
      "202       18          23  21485  \n",
      "203       26          27  22470  \n",
      "204       19          25  22625  \n",
      "\n",
      "[205 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['symboling', 'normalized_losses', 'make', 'fuel_type', 'aspiration', 'num_of_doors',\n",
    "          'body_style', 'drive_wheels', 'engine_location', 'wheel_base', 'length', 'width', \n",
    "           'height', 'curb_weight', 'engine_type', 'num_of_cylinders', 'engine_size', 'fuel_system',\n",
    "          'bore', 'stroke', 'compression', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', \n",
    "           'price']\n",
    "# Create a pandas DataFrame using the list of lists\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d8b79",
   "metadata": {},
   "source": [
    "### 5. Pandas Dataframe From Csv files\n",
    "\n",
    "<li>We can load a csv file and create a dataframe out of the data present inside a csv file using pandas.</li>\n",
    "<li>We have <b>.read_csv()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ac0ad",
   "metadata": {},
   "source": [
    "### Reading a csv file using skiprows and header parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3edcd087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    kfjkdfjskd     Unnamed: 1    Unnamed: 2 Unnamed: 3\n",
      "0  dfuhsdjufio            NaN           NaN        NaN\n",
      "1          day    temperature     windspeed      event\n",
      "2     1/1/2017             32             6       Rain\n",
      "3     1/4/2017  not available             9      Sunny\n",
      "4     1/5/2017             -1  not measured       Snow\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('./weather_data - weather_data.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a3a1c",
   "metadata": {},
   "source": [
    "#### Reading a csv file without header and giving names to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96c80601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-1</td>\n",
       "      <td>not measured</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>7</td>\n",
       "      <td>no event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>not measured</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/8/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>not measured</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>not measured</td>\n",
       "      <td>no event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/10/2017</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/12/2017</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/13/2017</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/14/2017</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Day    Temperature     Windspeed     Event\n",
       "0    1/1/2017             32             6      Rain\n",
       "1    1/4/2017  not available             9     Sunny\n",
       "2    1/5/2017             -1  not measured      Snow\n",
       "3    1/6/2017  not available             7  no event\n",
       "4    1/7/2017             32  not measured      Rain\n",
       "5    1/8/2017  not available  not measured     Sunny\n",
       "6    1/9/2017  not available  not measured  no event\n",
       "7   1/10/2017             34             8    Cloudy\n",
       "8   1/11/2017             -4            -1      Snow\n",
       "9   1/12/2017             26            12     Sunny\n",
       "10  1/13/2017             12            12     Rainy\n",
       "11  1/11/2017             -1            12      Snow\n",
       "12  1/14/2017             40            -1     Sunny"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a csv file without header and giving names to the columns\n",
    "columns=['Day','Temperature','Windspeed','Event']\n",
    "\n",
    "weather_df=pd.read_csv(\"./weather_data - weather_data.csv\",skiprows=3,names=columns)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fb6da",
   "metadata": {},
   "source": [
    "#### Read limited data from a csv file using nrows parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc08bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-1</td>\n",
       "      <td>not measured</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>not available</td>\n",
       "      <td>7</td>\n",
       "      <td>no event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>not measured</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day    Temperature     Windspeed     Event\n",
       "0  1/1/2017             32             6      Rain\n",
       "1  1/4/2017  not available             9     Sunny\n",
       "2  1/5/2017             -1  not measured      Snow\n",
       "3  1/6/2017  not available             7  no event\n",
       "4  1/7/2017             32  not measured      Rain"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df=pd.read_csv(\"./weather_data - weather_data.csv\",skiprows=3,nrows=5,header=None,names=columns)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b269e47",
   "metadata": {},
   "source": [
    "#### Reading csv files with na_values parameters ('weather_data.csv' file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25ca1258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/1/2017</th>\n",
       "      <th>32</th>\n",
       "      <th>6</th>\n",
       "      <th>Rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/2017</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/9/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/10/2017</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/12/2017</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/13/2017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/11/2017</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1/14/2017</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1/1/2017    32     6    Rain\n",
       "0    1/4/2017   NaN   9.0   Sunny\n",
       "1    1/5/2017  -1.0   NaN    Snow\n",
       "2    1/6/2017   NaN   7.0     NaN\n",
       "3    1/7/2017  32.0   NaN    Rain\n",
       "4    1/8/2017   NaN   NaN   Sunny\n",
       "5    1/9/2017   NaN   NaN     NaN\n",
       "6   1/10/2017  34.0   8.0  Cloudy\n",
       "7   1/11/2017  -4.0  -1.0    Snow\n",
       "8   1/12/2017  26.0  12.0   Sunny\n",
       "9   1/13/2017  12.0  12.0   Rainy\n",
       "10  1/11/2017  -1.0  12.0    Snow\n",
       "11  1/14/2017  40.0  -1.0   Sunny"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df=pd.read_csv(\"./weather_data - weather_data.csv\",skiprows=3,na_values=('not available','not measured','no event'))\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933041",
   "metadata": {},
   "source": [
    "#### Write a pandas dataframe to a csv file\n",
    "<li>We can write a pandas dataframe to a csv file using .to_csv() method.</li>\n",
    "<li>You can specify any name to the csv file while writing a pandas dataframe into a csv file.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e4cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv('weather-data0nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcbf58",
   "metadata": {},
   "source": [
    "### 6. Pandas Dataframe From Xcel files\n",
    "\n",
    "<li>We can load an excel file with <b>.xlsx</b> extension and create a dataframe out of the data present inside an excel file using pandas.</li>\n",
    "<li>We have <b>.read_excel()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>\n",
    "<li>We also need to install <b>openpyxl</b> for working with excel files.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f3b7c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        day  temperature  windspeed   event\n",
      "0            0   1/1/2017         32.0        6.0    Rain\n",
      "1            1   1/4/2017          NaN        9.0   Sunny\n",
      "2            2   1/5/2017         -1.0        NaN    Snow\n",
      "3            3   1/6/2017          NaN        7.0     NaN\n",
      "4            4   1/7/2017         32.0        NaN    Rain\n",
      "5            5   1/8/2017          NaN        NaN   Sunny\n",
      "6            6   1/9/2017          NaN        NaN     NaN\n",
      "7            7  1/10/2017         34.0        8.0  Cloudy\n",
      "8            8  1/11/2017         -4.0        NaN    Snow\n",
      "9            9  1/12/2017         26.0       12.0   Sunny\n",
      "10          10  1/13/2017         12.0       12.0   Rainy\n",
      "11          11  1/11/2017         -1.0       12.0    Snow\n",
      "12          12  1/14/2017         40.0        NaN   Sunny\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('./weather_data.xlsx')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ce1b",
   "metadata": {},
   "source": [
    "#### Writing to an excel file\n",
    "<li>We can write a pandas dataframe into a excel file using .to_excel() method.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14353c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully written to Excel file.\n"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel('./weather_data.xlsx', index=False)\n",
    "\n",
    "# Confirming the write operation\n",
    "print(\"DataFrame successfully written to Excel file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa283a0e",
   "metadata": {},
   "source": [
    "#### Using head() and tail() method to see top 5 and last 5 rows\n",
    "<li>To view the first few rows of our dataframe, we can use the DataFrame.head() method.</li>\n",
    "<li>By default, it returns the first five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>\n",
    "\n",
    "<li>Similarly, to view the last few rows of our dataframe, we can use the DataFrame.tail() method.</li>\n",
    "<li>By default, it returns the last five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0d11204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       day  temperature  windspeed  event\n",
      "0           0  1/1/2017         32.0        6.0   Rain\n",
      "1           1  1/4/2017          NaN        9.0  Sunny\n",
      "2           2  1/5/2017         -1.0        NaN   Snow\n",
      "3           3  1/6/2017          NaN        7.0    NaN\n",
      "4           4  1/7/2017         32.0        NaN   Rain\n"
     ]
    }
   ],
   "source": [
    "# View the first 5 rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e242384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        day  temperature  windspeed  event\n",
      "8            8  1/11/2017         -4.0        NaN   Snow\n",
      "9            9  1/12/2017         26.0       12.0  Sunny\n",
      "10          10  1/13/2017         12.0       12.0  Rainy\n",
      "11          11  1/11/2017         -1.0       12.0   Snow\n",
      "12          12  1/14/2017         40.0        NaN  Sunny\n"
     ]
    }
   ],
   "source": [
    "# View the last 5 rows of the DataFrame\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1955ec8",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "<li>Use the head() method to select the first 6 rows.</li>\n",
    "<li>Use the tail() method to select the last 8 rows.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aec28b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       day  temperature  windspeed  event\n",
      "0           0  1/1/2017         32.0        6.0   Rain\n",
      "1           1  1/4/2017          NaN        9.0  Sunny\n",
      "2           2  1/5/2017         -1.0        NaN   Snow\n",
      "3           3  1/6/2017          NaN        7.0    NaN\n",
      "4           4  1/7/2017         32.0        NaN   Rain\n",
      "5           5  1/8/2017          NaN        NaN  Sunny\n"
     ]
    }
   ],
   "source": [
    "# View the first 6 rows of the DataFrame\n",
    "print(df.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c51465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        day  temperature  windspeed   event\n",
      "5            5   1/8/2017          NaN        NaN   Sunny\n",
      "6            6   1/9/2017          NaN        NaN     NaN\n",
      "7            7  1/10/2017         34.0        8.0  Cloudy\n",
      "8            8  1/11/2017         -4.0        NaN    Snow\n",
      "9            9  1/12/2017         26.0       12.0   Sunny\n",
      "10          10  1/13/2017         12.0       12.0   Rainy\n",
      "11          11  1/11/2017         -1.0       12.0    Snow\n",
      "12          12  1/14/2017         40.0        NaN   Sunny\n"
     ]
    }
   ],
   "source": [
    "# View the last 8 rows of the DataFrame\n",
    "print(df.tail(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823ed4e",
   "metadata": {},
   "source": [
    "#### Finding the column names from the dataframe\n",
    "<li>We have df.columns attributes to check the name of columns in the pandas dataframe.</li>\n",
    "<li>Similarly, we have df.values attributes to check the data present in the pandas dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e4e6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['Unnamed: 0', 'day', 'temperature', 'windspeed', 'event'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Retrieve column names of the DataFrame\n",
    "column_names = df.columns\n",
    "\n",
    "# Display column names\n",
    "print(\"Column names:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "facd8863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of columns: Unnamed: 0       int64\n",
      "day             object\n",
      "temperature    float64\n",
      "windspeed      float64\n",
      "event           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Retrieve data types of columns\n",
    "column_data_types = df.dtypes\n",
    "\n",
    "# Display data types of columns\n",
    "print(\"Data types of columns:\", column_data_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be5a4aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array: [[0 '1/1/2017' 32.0 6.0 'Rain']\n",
      " [1 '1/4/2017' nan 9.0 'Sunny']\n",
      " [2 '1/5/2017' -1.0 nan 'Snow']\n",
      " [3 '1/6/2017' nan 7.0 nan]\n",
      " [4 '1/7/2017' 32.0 nan 'Rain']\n",
      " [5 '1/8/2017' nan nan 'Sunny']\n",
      " [6 '1/9/2017' nan nan nan]\n",
      " [7 '1/10/2017' 34.0 8.0 'Cloudy']\n",
      " [8 '1/11/2017' -4.0 nan 'Snow']\n",
      " [9 '1/12/2017' 26.0 12.0 'Sunny']\n",
      " [10 '1/13/2017' 12.0 12.0 'Rainy']\n",
      " [11 '1/11/2017' -1.0 12.0 'Snow']\n",
      " [12 '1/14/2017' 40.0 nan 'Sunny']]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve data from the DataFrame as a NumPy array\n",
    "data_array = df.values\n",
    "\n",
    "# Display data array\n",
    "print(\"Data array:\", data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dde5d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of DataFrame: 65\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the size of the DataFrame\n",
    "data_size = df.size\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(\"Size of DataFrame:\", data_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9b3d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced DataFrame:\n",
      "   Unnamed: 0       day  temperature\n",
      "0           0  1/1/2017         32.0\n",
      "1           1  1/4/2017          NaN\n",
      "2           2  1/5/2017         -1.0\n",
      "3           3  1/6/2017          NaN\n",
      "4           4  1/7/2017         32.0\n"
     ]
    }
   ],
   "source": [
    "# Slicing values from the DataFrame\n",
    "sliced_data = df.iloc[0:5, 0:3]  # Slicing first 5 rows and first 3 columns\n",
    "\n",
    "# Display the sliced data\n",
    "print(\"Sliced DataFrame:\")\n",
    "print(sliced_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f4e92",
   "metadata": {},
   "source": [
    "#### Checking the type of your dataframe \n",
    "<li>Another feature that makes pandas better for working with data is that dataframes can contain more than one data type.</li>\n",
    "<li>Axis values can have string labels, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with multiple data types: including integer, float, and string.</li>\n",
    "<li>We can use the DataFrame.dtypes attribute (similar to NumPy) to return information about the types of each column.</li>\n",
    "<li>When we import data, pandas attempts to guess the correct dtype for each column.</li>\n",
    "<li>Generally, pandas does well with this, which means we don't need to worry about specifying dtypes every time we start to work with data.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f7209ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "day             object\n",
       "temperature    float64\n",
       "windspeed      float64\n",
       "event           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df_nan=df.dtypes\n",
    "weather_df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518ae8e",
   "metadata": {},
   "source": [
    "#### Datatypes Information\n",
    "<li>We can get the shape of the dataset using <b>.shape()</b> method.</li>\n",
    "<li><b>.shape()</b> method returns the tuple datatype containing the number of rows and number of columns in the dataset.</li>\n",
    "<li>If we wanted an overview of all the dtypes used in our dataframe, we can use <b>.info()</b> method.</li>\n",
    "<li>Note that <b>DataFrame.info()</b> prints the information, rather than returning it, so we can't assign it to a variable.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf679a",
   "metadata": {},
   "source": [
    "#### Checking the null values in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18f9aca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in each column:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the DataFrame\n",
    "null_values = weather_df_nan.isnull().sum()\n",
    "\n",
    "# Display the count of null values in each column\n",
    "print(\"Null values in each column:\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444a637",
   "metadata": {},
   "source": [
    "#### set_index() and reset_index() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40ac34d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "         date  temperature  humidity\n",
      "0  2022-01-01           20        60\n",
      "1  2022-01-02           25        65\n",
      "2  2022-01-03           22        70\n",
      "3  2022-01-04           18        75\n",
      "\n",
      "DataFrame after setting 'date' column as index:\n",
      "            temperature  humidity\n",
      "date                             \n",
      "2022-01-01           20        60\n",
      "2022-01-02           25        65\n",
      "2022-01-03           22        70\n",
      "2022-01-04           18        75\n",
      "\n",
      "DataFrame after resetting index:\n",
      "         date  temperature  humidity\n",
      "0  2022-01-01           20        60\n",
      "1  2022-01-02           25        65\n",
      "2  2022-01-03           22        70\n",
      "3  2022-01-04           18        75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named weather_df_nan\n",
    "\n",
    "# Create a DataFrame\n",
    "weather_data = {\n",
    "    'date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04'],\n",
    "    'temperature': [20, 25, 22, 18],\n",
    "    'humidity': [60, 65, 70, 75]\n",
    "}\n",
    "weather_df_nan = pd.DataFrame(weather_data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(weather_df_nan)\n",
    "\n",
    "# Set the 'date' column as the index using set_index()\n",
    "weather_df_nan.set_index('date', inplace=True)\n",
    "print(\"\\nDataFrame after setting 'date' column as index:\")\n",
    "print(weather_df_nan)\n",
    "\n",
    "# Reset the index using reset_index()\n",
    "weather_df_nan.reset_index(inplace=True)\n",
    "print(\"\\nDataFrame after resetting index:\")\n",
    "print(weather_df_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c853",
   "metadata": {},
   "source": [
    "#### Selecting a column from a pandas DataFrame\n",
    "\n",
    "<li>Since our axis in pandas have labels, we can select data using those labels.</li> \n",
    "<li>Unlike in NumPy, we donot need to know the exact index location of a pandas dataframe.</li>\n",
    "<li>To do this, we can use the DataFrame.loc[] attribute. The syntax for DataFrame.loc[] is:</li>\n",
    "<code>\n",
    "df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "<li>We can use the following shortcut to select a single column:</li>\n",
    "<code>\n",
    "df[\"column_name\"]\n",
    "</code>\n",
    "\n",
    "<li>This style of selecting columns is very common.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89546f82",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "<li>Read <b>'appointment_schedule.csv'</b> file using pandas.</li>\n",
    "<li>Select the <b>'name'</b> column from the given dataset and store to <b>'appointment_names'</b> variable.</li>\n",
    "<li>Use Python's <b>type()</b> function to assign the type of name column to <b>name_type</b>.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b6c6872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few values of 'appointment_names':\n",
      "0    Joshua T. Blanton\n",
      "1      Jack T. Gutting\n",
      "2    Bradley T. Guiles\n",
      "3       Loryn F. Grieb\n",
      "4     Travis D. Gordon\n",
      "Name: name, dtype: object\n",
      "\n",
      "Type of 'name' column: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Read 'appointment_schedule.csv' file using pandas\n",
    "df = pd.read_csv('./appointment_schedule - appointment_schedule.csv')\n",
    "\n",
    "# Select the 'name' column\n",
    "appointment_names = df['name']\n",
    "\n",
    "# Assign the type of the 'name' column to 'name_type'\n",
    "name_type = type(appointment_names.iloc[0])\n",
    "\n",
    "# Print the first few values of 'appointment_names' and the type of 'name' column\n",
    "print(\"First few values of 'appointment_names':\")\n",
    "print(appointment_names.head())\n",
    "\n",
    "print(\"\\nType of 'name' column:\", name_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc59c3",
   "metadata": {},
   "source": [
    "#### Pandas Series\n",
    "<li>Series is the pandas type for one-dimensional objects.</li>\n",
    "<li>Anytime you see a 1D pandas object, it will be a series. Anytime you see a 2D pandas object, it will be a dataframe.</li>\n",
    "<li>A dataframe is a collection of series objects, which is similar to how pandas stores the data behind the scenes.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe1187",
   "metadata": {},
   "source": [
    "#### Adding a column in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "29ed0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name appointment_made_date app_start_date   app_end_date  \\\n",
      "0      Joshua T. Blanton    2014-12-18 0:00:00    1/6/15 9:30   1/6/15 23:59   \n",
      "1        Jack T. Gutting    2014-12-18 0:00:00    1/6/15 9:30   1/6/15 23:59   \n",
      "2      Bradley T. Guiles    2014-12-18 0:00:00    1/6/15 9:30   1/6/15 23:59   \n",
      "3         Loryn F. Grieb    2014-12-18 0:00:00    1/6/15 9:30   1/6/15 23:59   \n",
      "4       Travis D. Gordon    2014-12-18 0:00:00    1/6/15 9:30   1/6/15 23:59   \n",
      "..                   ...                   ...            ...            ...   \n",
      "580       Ryan J. Morgan    2015-01-09 0:00:00  1/16/15 10:00  1/16/15 23:59   \n",
      "581  Alexander V. Nevsky    2015-01-09 0:00:00  1/16/15 10:00  1/16/15 23:59   \n",
      "582   Montana J. Johnson    2015-01-09 0:00:00  1/16/15 10:00  1/16/15 23:59   \n",
      "583  Joseph A. Pritchard    2015-01-09 0:00:00  1/16/15 10:00  1/16/15 23:59   \n",
      "584      Martin O. Reina    2015-01-09 0:00:00  1/16/15 10:00  1/16/15 23:59   \n",
      "\n",
      "    visitee_namelast visitee_namefirst meeting_room  \\\n",
      "0                NaN             potus    west wing   \n",
      "1                NaN             potus    west wing   \n",
      "2                NaN             potus    west wing   \n",
      "3                NaN             potus    west wing   \n",
      "4                NaN             potus    west wing   \n",
      "..               ...               ...          ...   \n",
      "580              NaN             potus    west wing   \n",
      "581              NaN             potus    west wing   \n",
      "582              NaN             potus    west wing   \n",
      "583              NaN             potus    west wing   \n",
      "584              NaN             potus    west wing   \n",
      "\n",
      "                           description  name_length  \n",
      "0    JointService Military Honor Guard           17  \n",
      "1    JointService Military Honor Guard           15  \n",
      "2    JointService Military Honor Guard           17  \n",
      "3    JointService Military Honor Guard           14  \n",
      "4    JointService Military Honor Guard           16  \n",
      "..                                 ...          ...  \n",
      "580               military honor guard           14  \n",
      "581               military honor guard           19  \n",
      "582               military honor guard           18  \n",
      "583               military honor guard           19  \n",
      "584               military honor guard           15  \n",
      "\n",
      "[585 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'appointment_schedule.csv' file using pandas\n",
    "df = pd.read_csv('./appointment_schedule - appointment_schedule.csv')\n",
    "\n",
    "# Assuming you want to add a new column 'name_length' containing the length of names in the 'name' column\n",
    "df['name_length'] = df['name'].str.len()\n",
    "\n",
    "# Display the updated DataFrame with the new column\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410deeaa",
   "metadata": {},
   "source": [
    "### Selecting Multiple Columns From the DataFrame\n",
    "\n",
    "![](images/selecting_columns.png)\n",
    "\n",
    "<li>We can select multiple columns from the dataframe by using the following codes:</li>\n",
    "<code>\n",
    "    df.loc[:, [\"col1\", \"col2\"]]\n",
    "</code>\n",
    "\n",
    "<li>We can use syntax shortcuts for selecting multiple columns by using the following syntax:</li>\n",
    "<code>\n",
    "    df[[\"col1\", \"col2\"]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0439cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>2007</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>2007</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>2017</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year  selling_price  km_driven    fuel  \\\n",
       "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
       "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
       "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
       "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
       "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner  \n",
       "0  Individual       Manual   First Owner  \n",
       "1  Individual       Manual   First Owner  \n",
       "2  Individual       Manual   First Owner  \n",
       "3  Individual       Manual   First Owner  \n",
       "4  Individual       Manual  Second Owner  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_details_df = pd.read_csv('car_details.csv')\n",
    "car_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39f78cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  selling_price  km_driven\n",
       "0             Maruti 800 AC          60000      70000\n",
       "1  Maruti Wagon R LXI Minor         135000      50000\n",
       "2      Hyundai Verna 1.6 SX         600000     100000\n",
       "3    Datsun RediGO T Option         250000      46000\n",
       "4     Honda Amaze VX i-DTEC         450000     141000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_details_df.loc[:, ['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2356fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  selling_price  km_driven\n",
       "0             Maruti 800 AC          60000      70000\n",
       "1  Maruti Wagon R LXI Minor         135000      50000\n",
       "2      Hyundai Verna 1.6 SX         600000     100000\n",
       "3    Datsun RediGO T Option         250000      46000\n",
       "4     Honda Amaze VX i-DTEC         450000     141000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_details_df[['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5af7043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  selling_price  km_driven\n",
       "0             Maruti 800 AC          60000      70000\n",
       "1  Maruti Wagon R LXI Minor         135000      50000\n",
       "2      Hyundai Verna 1.6 SX         600000     100000\n",
       "3    Datsun RediGO T Option         250000      46000\n",
       "4     Honda Amaze VX i-DTEC         450000     141000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_details_limited = car_details_df.drop(['year', 'fuel', 'seller_type',\n",
    "                                          'transmission', 'owner'],\n",
    "                                          axis = 1)\n",
    "car_details_limited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb5f7",
   "metadata": {},
   "source": [
    "#### Selecting Rows From A Pandas DataFrame\n",
    "\n",
    "<li>Now that we've learned how to select columns by label, let's learn how to select rows using the labels of the index axis.</li>\n",
    "<li>We can use the same syntax to select rows from a dataframe as we do for columns:</li>\n",
    "<code>\n",
    "    df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "![](images/selecting_one_row.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbbda2",
   "metadata": {},
   "source": [
    "### Selecting Multiple Rows From the DataFrame\n",
    "\n",
    "![](images/selecting_multiple_rows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b1bca",
   "metadata": {},
   "source": [
    "#### Indexing & Slicing In Pandas DataFrame\n",
    "\n",
    "<li>We can slice a dataset from their rows as well as columns.</li>\n",
    "<li>If we have (5,5) shape data and we want first three rows and first three columns then we need to slice both rows and columns to get a desired shape.</li>\n",
    "<li>We have df.iloc() method which we can use to do indexing as well as slicing in a dataframe.</li>\n",
    "<li>Let's practice .iloc() method.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a6a6",
   "metadata": {},
   "source": [
    "#### Datatype Conversion In Pandas\n",
    "\n",
    "<li>Pandas astype() is the one of the most important methods. It is used to change data type of a series.</li>\n",
    "<li>When a pandas dataframe is created from a csv file,the data type is set automatically.</li>\n",
    "<li>The datatype will not be what it actually should be at times and this is where we can use astype()  to get desired datatype.</li>\n",
    "<li>For example, a salary column could be imported as string but to do operations we have to convert it into float.</li>\n",
    "<li>astype() is used to do such data type conversions.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e22cf7",
   "metadata": {},
   "source": [
    "#### Value Counts Method\n",
    "\n",
    "<li>Since series and dataframes are two distinct objects, they have their own unique methods.</li>\n",
    "\n",
    "<li>Let's look at an example of a series method - the Series.value_counts() method.</li>\n",
    "\n",
    "<li>This method displays each unique non-null value in a column and their counts in order.</li>\n",
    "\n",
    "<li>value_counts() is a series only method, we get the following error if we try to use it for dataframes:</li>\n",
    "\n",
    "<code>\n",
    "    AttributeError: 'DataFrame' object has no attribute 'value_counts'\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e21f7",
   "metadata": {},
   "source": [
    "#### Creating a frequency table from value_counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5254648",
   "metadata": {},
   "source": [
    "#### Renaming the column names in a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48a664",
   "metadata": {},
   "source": [
    "#### Selecting Items From A Series Method\n",
    "\n",
    "<li>As with dataframes, we can use Series.loc[] to select items from a series using single labels, a list, or a slice object.</li>\n",
    "<li>We can also omit loc[] and use bracket shortcuts for all three:</li>\n",
    "\n",
    "![](images/selecting_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bdfb5",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "<li>Use the value counts method to check the frequency count of different names from 'appointment_schedule.csv' file.</li>\n",
    "<li>Select only first row from the series.</li>\n",
    "<li>Select the first row and the last row from the series.</li>\n",
    "<li>Select the first five rows and the last five rows from the series.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5d6f3",
   "metadata": {},
   "source": [
    "#### DataFrame Vs DataSeries\n",
    "\n",
    "![](images/dataframe_vs_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a991f",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "![](images/pandas_selection_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58daf32",
   "metadata": {},
   "source": [
    "#### Vecotrized Operations In Pandas\n",
    "\n",
    "<li>We'll explore how pandas uses many of the concepts we learned in the NumPy.</li>\n",
    "<li>Because pandas is designed to operate like NumPy, a lot of concepts and methods from Numpy are supported.</li>\n",
    "<li>Recall that one of the ways NumPy makes working with data easier is with vectorized operations.</li>\n",
    "<li>Just like with NumPy, we can use any of the standard Python numeric operators with series, including:</li>\n",
    "<code>\n",
    "    series_a + series_b - Addition\n",
    "    series_a - series_b - Subtraction\n",
    "    series_a * series_b - Multiplication\n",
    "    series_a / series_b - Division\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0db341",
   "metadata": {},
   "source": [
    "#### Some Statistical Functions In Pandas\n",
    "\n",
    "<li>Like NumPy, Pandas supports many descriptive stats methods such as mean, median, mode, min, max and so on.</li>\n",
    "<li>Here are a few of the most useful ones.</li>\n",
    "<code>\n",
    "Series.max()\n",
    "Series.min()\n",
    "Series.mean()\n",
    "Series.median()\n",
    "Series.mode()\n",
    "Series.sum()\n",
    "</code>\n",
    "<li>We can calculate the average value of a particular column(series) using df.column_name.mean().</li>\n",
    "<li>For calculating the minimum value in a particular column(series), we can use df.column_name.min().</li>\n",
    "<li>Similarly, for calculating the maximum value in a particular column(series), we can use df.column_name.max().</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6ea53",
   "metadata": {},
   "source": [
    "#### Finding the descriptive statistics of the dataframe using .describe() method\n",
    "\n",
    "<li>Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values.</li>\n",
    "<li>describe() method in Pandas is used to compute descriptive statistics for all of your numeric columns.</li>\n",
    "<li>Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types.</li>\n",
    "<li>The output will vary depending on what is provided.</li>\n",
    "<li>If we want to see the descriptive statistics of an object datatype then we have to specify <b>df.describe(include = \"O\")</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2ba4a",
   "metadata": {},
   "source": [
    "#### Assigning Values With Pandas\n",
    "\n",
    "<li>Just like in NumPy, the same techniques that we use to select data could be used for assignment.</li>\n",
    "\n",
    "<li>When we selected a whole column by label and used assignment, we assigned the value to every item in that column.</li>\n",
    "\n",
    "<li>By providing labels for both axes, we can assign them to a single value within our dataframe.</li>\n",
    "\n",
    "<code>\n",
    "    df.loc[row_label, col_label] = assignment_value\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e91d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aede61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf9b17d",
   "metadata": {},
   "source": [
    "#### Using Boolean Indexing With Pandas Objects (Selection With Condition In Pandas)\n",
    "<li>We can assign a value by using row label and column label in pandas.</li>\n",
    "<li>But what if we need to assign a same value to a group of similar rows with the same criteria.</li>\n",
    "<li> Instead, we can use boolean indexing to change all rows that meet the same criteria, just like we did with NumPy.</li>\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>Equals: df['series'] == value</li>\n",
    "    <li>Not Equals: df['series'] != value</li>\n",
    "    <li>Less than: df['series'] < value</li>\n",
    "    <li>Less than or equal to: df['series'] <= value</li>\n",
    "    <li>Greater than: df['series'] > value</li>\n",
    "    <li>Greater than or equal to: df['series'] >= value</li>\n",
    "</ol>\n",
    "<li>These conditions can be used in several ways, most commonly inside .loc to select values with conditions.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feeff6",
   "metadata": {},
   "source": [
    "### Using Pandas Method To Create a Boolean Mask\n",
    "\n",
    "<li>In the last couple lessons, we used Python boolean operators to create boolean masks to select subsets of data.</li>\n",
    "    \n",
    "<li>There are also a number of pandas methods that return boolean masks useful for exploring data.</li>\n",
    "\n",
    "<li>Two examples are the Series.isnull() method and Series.notnull() method.</li>\n",
    "<li>Series.isnull() method can be used to select either rows that contain null (or NaN) values for a certain column.</li>\n",
    "<li>Similarly, Series.notnull() method is used to select rows that do not contain null values for a certain column.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f9989",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "<li>Read 'Fortune_1000.csv' file using pandas read_csv() method and store it in a variable named f1000.</li>\n",
    "<li>Select the rank, revenues, and rank_change columns in f1000. Then, use the df.head() method to select first five rows.</li>\n",
    "<li>Select just the fifth row of the f1000 dataframe. Assign the result to fifth_row using iloc.</li>\n",
    "<li>Select the value in first row of the company column. Assign the result to company_value.</li>\n",
    "<li>Select the last three rows of the f1000 dataframe. Assign the result to last_three_rows.</li>\n",
    "<li>Select the first to seventh rows and the first five columns of the f1000 dataframe.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "492ba182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the DataFrame:\n",
      "Index(['rank', 'title', 'Previous Rank', 'Revenues ($M)', 'Revenue Change',\n",
      "       'Profits ($M)', 'Profit Change', 'Assets ($M)',\n",
      "       'Mkt Value as of 3/29/18 ($M)', 'Employees', 'CEO', 'CEO Title',\n",
      "       'Sector', 'Industry', 'Years on Fortune 500 List', 'City', 'State',\n",
      "       'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "\n",
      "First five rows with selected columns:\n",
      "   rank Revenues ($M) Previous Rank\n",
      "0     1     $500,343              1\n",
      "1     2     $244,363              4\n",
      "2     3     $242,137              2\n",
      "3     4     $229,234              3\n",
      "4     5     $201,159              6\n",
      "\n",
      "Fifth row:\n",
      "rank                                                                  5\n",
      "title                                                UnitedHealth Group\n",
      "Previous Rank                                                         6\n",
      "Revenues ($M)                                                 $201,159 \n",
      "Revenue Change                                                    8.80%\n",
      "Profits ($M)                                                $10,558.00 \n",
      "Profit Change                                                    50.50%\n",
      "Assets ($M)                                                   $139,058 \n",
      "Mkt Value as of 3/29/18 ($M)                                  $207,080 \n",
      "Employees                                                       260,000\n",
      "CEO                                                   David S. Wichmann\n",
      "CEO Title                           Chairman &  Chief Executive Officer\n",
      "Sector                                                      Health Care\n",
      "Industry                        Health Care: Insurance and Managed Care\n",
      "Years on Fortune 500 List                                            24\n",
      "City                                                         Minnetonka\n",
      "State                                                                MN\n",
      "Latitude                                                      44.921184\n",
      "Longitude                                                    -93.468749\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Value in the first row of the company column: Walmart\n",
      "\n",
      "Last three rows:\n",
      "     rank         title Previous Rank Revenues ($M) Revenue Change  \\\n",
      "997   998     CoreLogic           952       $1,851          -5.20%   \n",
      "998   999  Ensign Group           NaN       $1,849          11.80%   \n",
      "999  1000           HCP           798       $1,848         -27.20%   \n",
      "\n",
      "    Profits ($M) Profit Change Assets ($M) Mkt Value as of 3/29/18 ($M)  \\\n",
      "997     $152.20         42.80%     $4,077                       $3,694    \n",
      "998      $40.50        -19.00%     $1,102                       $1,354    \n",
      "999     $414.20        -34.00%    $14,089                      $10,910    \n",
      "\n",
      "    Employees                         CEO  \\\n",
      "997     5,900            Frank D. Martell   \n",
      "998    21,301  Christopher R. Christensen   \n",
      "999       190            Thomas M. Herzog   \n",
      "\n",
      "                                          CEO Title             Sector  \\\n",
      "997  President, Chief Executive Officer &  Director  Business Services   \n",
      "998  President, Chief Executive Officer &  Director        Health Care   \n",
      "999  President, Chief Executive Officer &  Director         Financials   \n",
      "\n",
      "                            Industry Years on Fortune 500 List           City  \\\n",
      "997          Financial Data Services                         -         Irvine   \n",
      "998  Health Care: Medical Facilities                         -  Mission Viejo   \n",
      "999                      Real estate                         -         Irvine   \n",
      "\n",
      "    State   Latitude   Longitude  \n",
      "997    CA  33.684567 -117.826505  \n",
      "998    CA  33.596891 -117.658156  \n",
      "999    CA  33.684567 -117.826505  \n",
      "\n",
      "First to seventh rows and first five columns:\n",
      "   rank               title Previous Rank Revenues ($M) Revenue Change\n",
      "0     1             Walmart             1     $500,343           3.00%\n",
      "1     2         Exxon Mobil             4     $244,363          17.40%\n",
      "2     3  Berkshire Hathaway             2     $242,137           8.30%\n",
      "3     4               Apple             3     $229,234           6.30%\n",
      "4     5  UnitedHealth Group             6     $201,159           8.80%\n",
      "5     6            McKesson             5     $198,533           3.10%\n",
      "6     7          CVS Health             7     $184,765           4.10%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'Fortune_1000.csv' file using pandas read_csv() method and store it in a variable named f1000\n",
    "f1000 = pd.read_csv('./fortune1000-final.csv')\n",
    "\n",
    "# Check the column names in the DataFrame\n",
    "print(\"Column names in the DataFrame:\")\n",
    "print(f1000.columns)\n",
    "\n",
    "# Adjust the column names accordingly\n",
    "selected_columns = ['rank', 'Revenues ($M)', 'Previous Rank']\n",
    "# Select the rank, revenues, and rank_change columns in f1000. Then, use the df.head() method to select first five rows.\n",
    "first_five_rows = f1000[selected_columns].head()\n",
    "print(\"\\nFirst five rows with selected columns:\")\n",
    "print(first_five_rows)\n",
    "\n",
    "# Select just the fifth row of the f1000 dataframe. Assign the result to fifth_row using iloc.\n",
    "fifth_row = f1000.iloc[4]  # Note that iloc is 0-based index, so index 4 refers to the fifth row\n",
    "print(\"\\nFifth row:\")\n",
    "print(fifth_row)\n",
    "\n",
    "# Select the value in first row of the company column. Assign the result to company_value.\n",
    "company_value = f1000.loc[0, 'title']\n",
    "print(\"\\nValue in the first row of the company column:\", company_value)\n",
    "\n",
    "# Select the last three rows of the f1000 dataframe. Assign the result to last_three_rows.\n",
    "last_three_rows = f1000.tail(3)\n",
    "print(\"\\nLast three rows:\")\n",
    "print(last_three_rows)\n",
    "\n",
    "# Select the first to seventh rows and the first five columns of the f1000 dataframe.\n",
    "selected_rows_and_columns = f1000.iloc[0:7, 0:5]\n",
    "print(\"\\nFirst to seventh rows and first five columns:\")\n",
    "print(selected_rows_and_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e903aad",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "<li>Use the Series.isnull() method to select all rows from f1000 that have a null value for the prev_rank column.</li>\n",
    "<li>Select only the company, rank, and previous_rank columns where previous_rank column is null.</li>\n",
    "<li>Use the Series.notnull() method to select all rows from f1000 that have a non-null value for the previous_rank column.</li></b>\n",
    "<li>From the previously_ranked dataframe, subtract the rank column from the previous_rank column.</li>\n",
    "<li>Assign the values in the rank_change to a new column in the f1000 dataframe, \"rank_change\".</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c7ede9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'Previous Rank' column: object\n",
      "   rank               title  Previous Rank Revenues ($M) Revenue Change  \\\n",
      "0     1             Walmart            1.0     $500,343           3.00%   \n",
      "1     2         Exxon Mobil            4.0     $244,363          17.40%   \n",
      "2     3  Berkshire Hathaway            2.0     $242,137           8.30%   \n",
      "3     4               Apple            3.0     $229,234           6.30%   \n",
      "4     5  UnitedHealth Group            6.0     $201,159           8.80%   \n",
      "\n",
      "  Profits ($M) Profit Change Assets ($M) Mkt Value as of 3/29/18 ($M)  \\\n",
      "0   $9,862.00        -27.70%   $204,522                     $263,563    \n",
      "1  $19,710.00        151.40%   $348,691                     $316,157    \n",
      "2  $44,940.00         86.70%   $702,095                     $492,008    \n",
      "3  $48,351.00          5.80%   $375,319                     $851,318    \n",
      "4  $10,558.00         50.50%   $139,058                     $207,080    \n",
      "\n",
      "   Employees                  CEO  \\\n",
      "0  2,300,000  C. Douglas McMillon   \n",
      "1     71,200      Darren W. Woods   \n",
      "2    377,000    Warren E. Buffett   \n",
      "3    123,000      Timothy D. Cook   \n",
      "4    260,000    David S. Wichmann   \n",
      "\n",
      "                                        CEO Title       Sector  \\\n",
      "0  President, Chief Executive Officer &  Director    Retailing   \n",
      "1             Chairman &  Chief Executive Officer       Energy   \n",
      "2  Chairman, President &  Chief Executive Officer   Financials   \n",
      "3             Chairman &  Chief Executive Officer   Technology   \n",
      "4             Chairman &  Chief Executive Officer  Health Care   \n",
      "\n",
      "                                   Industry Years on Fortune 500 List  \\\n",
      "0                     General Merchandisers                        24   \n",
      "1                        Petroleum Refining                        24   \n",
      "2  Insurance: Property and Casualty (Stock)                        24   \n",
      "3               Computers, Office Equipment                        24   \n",
      "4   Health Care: Insurance and Managed Care                        24   \n",
      "\n",
      "          City State   Latitude   Longitude  rank_change  \n",
      "0  Bentonville    AR  36.372854  -94.208817          0.0  \n",
      "1       Irving    TX  32.814018  -96.948894          2.0  \n",
      "2        Omaha    NE  41.256537  -95.934503         -1.0  \n",
      "3    Cupertino    CA  37.322998 -122.032182         -1.0  \n",
      "4   Minnetonka    MN  44.921184  -93.468749          1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'Fortune_1000.csv' file using pandas read_csv() method and store it in a variable named f1000\n",
    "f1000 = pd.read_csv('./fortune1000-final.csv')\n",
    "\n",
    "# Check the data type of the 'Previous Rank' column\n",
    "print(\"Data type of 'Previous Rank' column:\", f1000['Previous Rank'].dtype)\n",
    "\n",
    "# Convert 'Previous Rank' column to numeric if it's not already\n",
    "f1000['Previous Rank'] = pd.to_numeric(f1000['Previous Rank'], errors='coerce')\n",
    "\n",
    "# Use the Series.isnull() method to select all rows from f1000 that have a null value for the prev_rank column.\n",
    "null_prev_rank_rows = f1000[f1000['Previous Rank'].isnull()]\n",
    "\n",
    "# Select only the company, rank, and previous_rank columns where previous_rank column is null.\n",
    "null_prev_rank_data = null_prev_rank_rows[['title', 'rank', 'Previous Rank']]\n",
    "\n",
    "# Use the Series.notnull() method to select all rows from f1000 that have a non-null value for the previous_rank column.\n",
    "non_null_prev_rank_rows = f1000[f1000['Previous Rank'].notnull()]\n",
    "\n",
    "# From the previously_ranked dataframe, subtract the rank column from the previous_rank column.\n",
    "previously_ranked = non_null_prev_rank_rows.copy()\n",
    "previously_ranked['rank_change'] = previously_ranked['Previous Rank'] - previously_ranked['rank']\n",
    "\n",
    "# Assign the values in the rank_change to a new column in the f1000 dataframe, \"rank_change\".\n",
    "f1000['rank_change'] = previously_ranked['rank_change']\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(f1000.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a3f21",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "<li>Select all companies with revenues over 100 thousands and negative profits from the f1000 dataframe.</li>\n",
    "\n",
    "##### Instructions\n",
    "\n",
    "<li>Create a boolean array that selects the companies with revenues greater than 100 thousands.</li>\n",
    "<li>Create a boolean array that selects the companies with profits less than 0.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44715085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rank, title, Previous Rank, Revenues ($M), Revenue Change, Profits ($M), Profit Change, Assets ($M), Mkt Value as of 3/29/18 ($M), Employees, CEO, CEO Title, Sector, Industry, Years on Fortune 500 List, City, State, Latitude, Longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'fortune1000-final.csv' file using pandas read_csv() method and store it in a variable named f1000\n",
    "f1000 = pd.read_csv('fortune1000-final.csv')\n",
    "\n",
    "# Convert 'Revenues ($M)' column to numeric type, coerce errors to NaN for non-numeric values\n",
    "f1000['Revenues ($M)'] = pd.to_numeric(f1000['Revenues ($M)'], errors='coerce')\n",
    "\n",
    "# Convert 'Profits ($M)' column to numeric type, coerce errors to NaN for non-numeric values\n",
    "f1000['Profits ($M)'] = pd.to_numeric(f1000['Profits ($M)'], errors='coerce')\n",
    "\n",
    "# Create a boolean array that selects the companies with revenues greater than 100 thousands\n",
    "revenues_gt_100k = f1000['Revenues ($M)'] > 100\n",
    "\n",
    "# Create a boolean array that selects the companies with profits less than 0\n",
    "negative_profits = f1000['Profits ($M)'] < 0\n",
    "\n",
    "# Select all companies with revenues over 100 thousands and negative profits from the f1000 dataframe\n",
    "selected_companies = f1000[revenues_gt_100k & negative_profits]\n",
    "\n",
    "# Display selected companies\n",
    "print(selected_companies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f0aa4",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "<li>Select all rows for companies whose city value is either Brazil or Venezuela.</li>\n",
    "<li>Select the first five companies in the Technology sector for which the city is not the \"Boston\" from the f1000 dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9cd34e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies in Brazil or Venezuela:\n",
      "Empty DataFrame\n",
      "Columns: [rank, title, Previous Rank, Revenues ($M), Revenue Change, Profits ($M), Profit Change, Assets ($M), Mkt Value as of 3/29/18 ($M), Employees, CEO, CEO Title, Sector, Industry, Years on Fortune 500 List, City, State, Latitude, Longitude]\n",
      "Index: []\n",
      "\n",
      "First five Technology sector companies (excluding Boston):\n",
      "    rank              title Previous Rank Revenues ($M) Revenue Change  \\\n",
      "3      4              Apple             3     $229,234           6.30%   \n",
      "21    22           Alphabet            27     $110,855          22.80%   \n",
      "29    30          Microsoft            28      $89,950           5.40%   \n",
      "33    34                IBM            32      $79,139          -1.00%   \n",
      "34    35  Dell Technologies            41      $78,660          21.40%   \n",
      "\n",
      "   Profits ($M) Profit Change Assets ($M) Mkt Value as of 3/29/18 ($M)  \\\n",
      "3   $48,351.00          5.80%   $375,319                     $851,318    \n",
      "21  $12,662.00        -35.00%   $197,295                     $719,124    \n",
      "29  $21,204.00         26.20%   $241,086                     $702,760    \n",
      "33   $5,753.00        -51.50%   $125,356                     $141,335    \n",
      "34  ($3,728.00)             -   $122,281                             -   \n",
      "\n",
      "   Employees                  CEO  \\\n",
      "3    123,000      Timothy D. Cook   \n",
      "21    80,110           Larry Page   \n",
      "29   124,000        Satya Nadella   \n",
      "33   397,800  Virginia M. Rometty   \n",
      "34   145,000      Michael S. Dell   \n",
      "\n",
      "                                         CEO Title      Sector  \\\n",
      "3              Chairman &  Chief Executive Officer  Technology   \n",
      "21             Chief Executive Officer &  Director  Technology   \n",
      "29             Chief Executive Officer &  Director  Technology   \n",
      "33  Chairman, President &  Chief Executive Officer  Technology   \n",
      "34             Chairman &  Chief Executive Officer  Technology   \n",
      "\n",
      "                           Industry Years on Fortune 500 List           City  \\\n",
      "3       Computers, Office Equipment                        24      Cupertino   \n",
      "21  Internet Services and Retailing                        13  Mountain View   \n",
      "29                Computer Software                        24        Redmond   \n",
      "33  Information Technology Services                        24         Armonk   \n",
      "34      Computers, Office Equipment                        21     Round Rock   \n",
      "\n",
      "   State   Latitude   Longitude  \n",
      "3     CA  37.322998 -122.032182  \n",
      "21    CA  37.386052 -122.083851  \n",
      "29    WA  47.673988 -122.121512  \n",
      "33    NY  41.126485  -73.714020  \n",
      "34    TX  30.508255  -97.678896  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'fortune1000-final.csv' file using pandas read_csv() method and store it in a variable named f1000\n",
    "f1000 = pd.read_csv('fortune1000-final.csv')\n",
    "\n",
    "# Select all rows for companies whose city value is either Brazil or Venezuela.\n",
    "selected_countries = f1000[(f1000['City'] == 'Brazil') | (f1000['City'] == 'Venezuela')]\n",
    "\n",
    "# Display selected rows\n",
    "print(\"Companies in Brazil or Venezuela:\")\n",
    "print(selected_countries)\n",
    "\n",
    "# Select the first five companies in the Technology sector for which the city is not \"Boston\".\n",
    "selected_tech_companies = f1000[(f1000['Sector'] == 'Technology') & (f1000['City'] != 'Boston')].head(5)\n",
    "\n",
    "# Display selected rows\n",
    "print(\"\\nFirst five Technology sector companies (excluding Boston):\")\n",
    "print(selected_tech_companies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e66d65",
   "metadata": {},
   "source": [
    "#### Sorting Values\n",
    "<li>We can use the DataFrame.sort_values() method to sort the rows on a particular column.</li>\n",
    "<li>To do so, we pass the column name to the method:</li>\n",
    "<code>\n",
    "sorted_rows = df.sort_values(\"column_name\")\n",
    "</code>\n",
    "<li>By default, the sort_values() method will sort the rows in ascending order  from smallest to largest.</li>\n",
    "<li>To sort the rows in descending order instead, we can set the ascending parameter to False:</li>\n",
    "<code>\n",
    "    sorted_rows = df.sort_values(\"column_name\", ascending=False)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45766113",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'Fortune_1000.csv' using pandas read_csv() method.</li>\n",
    "<li>Find the company headquartered in Los Angeles with the largest number of employees.</li>\n",
    "<li>Select only the rows that have a city name equal to Los Angeles.</li>\n",
    "<li>Use DataFrame.sort_values() to sort those rows by the employees column in descending order.</li>\n",
    "<li>Use DataFrame.iloc[] to select the first row from the sorted dataframe.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33ac335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company headquartered in Los Angeles with the largest number of employees:\n",
      "rank                                                            930\n",
      "title                                         Oaktree Capital Group\n",
      "Previous Rank                                                   NaN\n",
      "Revenues ($M)                                               $2,100 \n",
      "Revenue Change                                               38.30%\n",
      "Profits ($M)                                               $231.50 \n",
      "Profit Change                                                18.90%\n",
      "Assets ($M)                                                 $9,015 \n",
      "Mkt Value as of 3/29/18 ($M)                                $6,188 \n",
      "Employees                                                       930\n",
      "CEO                                                  Jay S. Wintrob\n",
      "CEO Title                       Chairman &  Chief Executive Officer\n",
      "Sector                                                   Financials\n",
      "Industry                                                 Securities\n",
      "Years on Fortune 500 List                                         -\n",
      "City                                                    Los Angeles\n",
      "State                                                            CA\n",
      "Latitude                                                  34.052234\n",
      "Longitude                                               -118.243685\n",
      "Name: 929, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'Fortune_1000.csv' using pandas read_csv() method\n",
    "f1000 = pd.read_csv('fortune1000-final.csv')\n",
    "\n",
    "# Select only the rows that have a city name equal to Los Angeles\n",
    "los_angeles_companies = f1000[f1000['City'] == 'Los Angeles']\n",
    "\n",
    "# Use DataFrame.sort_values() to sort those rows by the employees column in descending order\n",
    "sorted_los_angeles_companies = los_angeles_companies.sort_values(by='Employees', ascending=False)\n",
    "\n",
    "# Use DataFrame.iloc[] to select the first row from the sorted dataframe\n",
    "company_with_most_employees_in_LA = sorted_los_angeles_companies.iloc[0]\n",
    "\n",
    "# Print the company with the largest number of employees headquartered in Los Angeles\n",
    "print(\"Company headquartered in Los Angeles with the largest number of employees:\")\n",
    "print(company_with_most_employees_in_LA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa1f3f",
   "metadata": {},
   "source": [
    "### String Manipulation In Pandas DataFrame\n",
    "\n",
    "<li>String manipulation is the process of changing, parsing, splitting, 'cleaning' or analyzing strings.</li>\n",
    "<li>As we know that sometimes, data in the string is not suitable for manipulating the analysis or get a description of the data.</li>\n",
    "<li>But Python is known for its ability to manipulate strings.</li>\n",
    "<li>Pandas provides us the ways to manipulate to modify and process string data-frame using some builtin functions.</li>\n",
    "<li>Some of the most useful pandas string processing functions are as follows:</li>\n",
    "<ol>\n",
    "    <li><b>lower()</b></li>\n",
    "    <li><b>upper()</b></li>\n",
    "    <li><b>islower()</b></li>\n",
    "    <li><b>isupper()</b></li>\n",
    "    <li><b>isnumeric()</b></li>\n",
    "    <li><b>strip()</b></li>\n",
    "    <li><b>split()</b></li>\n",
    "    <li><b>len()</b></li>\n",
    "    <li><b>get_dummies()</b></li>\n",
    "    <li><b>startswith()</b></li>\n",
    "    <li><b>endswith()</b></li>\n",
    "    <li><b>replace()</b></li>\n",
    "    <li><b>contains()</b></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8f9ac",
   "metadata": {},
   "source": [
    "#### 1. lower(): \n",
    "<li>It converts all uppercase characters in strings in the dataframe to lower case and returns the lowercase strings in the result.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716b946",
   "metadata": {},
   "source": [
    "#### 2. upper():\n",
    "<li>It converts all lowercase characters in strings in the dataframe to upper case and returns the uppercase strings in result.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086d672",
   "metadata": {},
   "source": [
    "#### 3. islower(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in lower case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1f5d1",
   "metadata": {},
   "source": [
    "#### 4. isupper(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in upper case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fcf07",
   "metadata": {},
   "source": [
    "#### 5. isnumeric():\n",
    "<li>It checks whether all characters in each string in the Data-Frame are numeric or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db0288",
   "metadata": {},
   "source": [
    "#### 6. strip():\n",
    "<li>If there are spaces at the beginning or end of a string, we should trim the strings to eliminate spaces using strip() method.</li>\n",
    "<li>It remove the extra spaces contained by a string in a DataFrame.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0cc7b",
   "metadata": {},
   "source": [
    "#### 7. split( ):\n",
    "<li>It splits each string with the given pattern.</li>\n",
    "<li>Strings are split and the new elements after the performed split operation, are stored in a list.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0786d86",
   "metadata": {},
   "source": [
    "#### 8. len():\n",
    "<li>With the help of len() we can compute the length of each string in DataFrame.</li>\n",
    "<li>If there is empty data in a DataFrame, it returns NaN.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866234b9",
   "metadata": {},
   "source": [
    "#### 9. get_dummies(): \n",
    "<li>It returns the DataFrame with One-Hot Encoded values like we can see that it returns boolean value 1 if it exists in relative index or 0 if not exists.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53501fa7",
   "metadata": {},
   "source": [
    "#### 10. startswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index starts with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that startswith 'ind' then you can specify df[df[col].str.startswith('ind')</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d7983",
   "metadata": {},
   "source": [
    "#### 11. endswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index ends with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that ends with 'es' then you can specify df[df[col].str.endswith('es')</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85f839",
   "metadata": {},
   "source": [
    "#### 12. replace(a,b):\n",
    "<li>It replaces the value a with the value b.</li>\n",
    "<li>If you wanted to remove white space characters then you can use replace() method as:</li>\n",
    "<code>\n",
    "df[col_name].str.replace(\" \", \"\")\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272a938",
   "metadata": {},
   "source": [
    "#### 13. contains():\n",
    "<li>contains() method checks whether the string contains a particular substring or not.</li>\n",
    "<li>The function is quite similar to replace() but instead of replacing the string itself it just returns the boolean value True or False.</li>\n",
    "<li>If a substring is present in a string, then it returns boolean value True else False.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5a6dc",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "<li>We can use fillna() method in pandas to fill missing values using different ways.</li>\n",
    "<li>We can use interpolation method to make a guess on missing values.</li>\n",
    "<li>We can use dropna() method to drop rows with missing values.</li>\n",
    "<li>We can also fill missing values with the mean value, median value or the mode value depending on the values of columns.</li>\n",
    "<li>Filling missing values with mean and median is appropriate when the column has continuous values.</li>\n",
    "<li>If the data is categorical then filling missing values with mode is a good idea.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b01ebc",
   "metadata": {},
   "source": [
    "#### fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793078",
   "metadata": {},
   "source": [
    "#### fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e2c03",
   "metadata": {},
   "source": [
    "#### Interpolate(Linear Interpolation)\n",
    "<li>method = time</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3062",
   "metadata": {},
   "source": [
    "#### dropna()\n",
    "<li>dropna() with how and threshold parameter</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2760f62",
   "metadata": {},
   "source": [
    "#### Handle Missing Values using .replace() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c419fb9",
   "metadata": {},
   "source": [
    "#### Replacing Values Using a Dictionary (using columns and without using columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0dbe0",
   "metadata": {},
   "source": [
    "#### Replacing values using a regex\n",
    "<code>\n",
    "df.replace(original_value, replaced_value, regex = True)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7f35d",
   "metadata": {},
   "source": [
    "#### Mapping values of a particular column using replace method\n",
    "<li>Replacing the list of values using another list of values</li>\n",
    "<li>Replacing values of a particular column using a dictionary</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1988ee8",
   "metadata": {},
   "source": [
    "#### GroupBy Functions\n",
    "<li>Pandas groupby is used for grouping the data according to the categories and apply a function to the categories.</li>\n",
    "<li>It also helps to aggregate data efficiently.</li>\n",
    "<li>Pandas dataframe.groupby() function is used to split the data into groups based on some criteria.</li>\n",
    "<code>\n",
    "    df.groupby(col_name, as_index, sort, dropna)\n",
    "</code>\n",
    "<li>It uses split, apply, combine principle to create a groupby dataframe.</li>\n",
    "<li>The groupby function accepts multiple parameters. Some of them are as follows:</li>\n",
    "<ol>\n",
    "    <li>col_name(required): the name of column against which you want to group elements.</li>\n",
    "    <li>as_index(optional): default = True, if you want to include groupby column as an index set it        to True else False.</li>\n",
    "    <li>sort(optional): default = True, if you want to sort the group based on keys then keep it as       True else False.</li>\n",
    "    <li>dropna(optional): default = True, if you keep it as false then it will also include Nan values     as a separate group.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c395f",
   "metadata": {},
   "source": [
    "### GroupBy Aggregation Functions\n",
    "<li>Here are some of the aggregating functions available in Pandas and quick summary of what it does.</li>\n",
    "<ol>\n",
    "    <li>mean(): Compute mean of groups for numeric columns</li>\n",
    "    <li>sum(): Compute sum of group values for numeric columns</li>\n",
    "    <li>size(): Compute group sizes</li>\n",
    "    <li>count(): Compute count of group</li>\n",
    "    <li>std(): Standard deviation of groups for numeric columns</li>\n",
    "    <li>var(): Compute variance of groups for numeric columns</li>\n",
    "    <li>describe(): Generates descriptive statistics</li>\n",
    "    <li>first(): Compute first of group values</li>\n",
    "    <li>last(): Compute last of group values</li>\n",
    "    <li>nth() : Take nth value, or a subset if n is a list</li>\n",
    "    <li>min(): Compute min of group values</li>\n",
    "    <li>max(): Compute max of group values</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3bf7e",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'car_details.csv' file and create a pandas dataframe from this file.</li>\n",
    "<li>Find the maximum price for each of the car brand.</li>\n",
    "<li>Find the average price for each of the fuel types.</li>\n",
    "<li>Find the average km_driven for each of the seller_types.</li>\n",
    "<li>Find the count of each of the car names.</li>\n",
    "<li>Find the maximum km_driven for each of the owner types.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb7517fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum price for each car brand:\n",
      "name\n",
      "Ambassador CLASSIC 1500 DSL AC           120000\n",
      "Ambassador Classic 2000 Dsz               50000\n",
      "Ambassador Grand 1800 ISZ MPFI PW CL     430000\n",
      "Audi A4 1.8 TFSI                        1200000\n",
      "Audi A4 2.0 TDI                         1295000\n",
      "                                         ...   \n",
      "Volkswagen Vento Petrol Highline AT      300000\n",
      "Volvo V40 D3 R Design                   1975000\n",
      "Volvo XC 90 D5 Inscription BSIV         4500000\n",
      "Volvo XC60 D3 Kinetic                   1750000\n",
      "Volvo XC60 D5 Inscription               2000000\n",
      "Name: selling_price, Length: 1491, dtype: int64\n",
      "\n",
      "Average price for each fuel type:\n",
      "fuel\n",
      "CNG         277174.925000\n",
      "Diesel      669094.252206\n",
      "Electric    310000.000000\n",
      "LPG         167826.043478\n",
      "Petrol      344840.137541\n",
      "Name: selling_price, dtype: float64\n",
      "\n",
      "Average km driven for each seller type:\n",
      "seller_type\n",
      "Dealer              52827.259557\n",
      "Individual          71167.556104\n",
      "Trustmark Dealer    39202.215686\n",
      "Name: km_driven, dtype: float64\n",
      "\n",
      "Count of each car name:\n",
      "name\n",
      "Maruti Swift Dzire VDI                     69\n",
      "Maruti Alto 800 LXI                        59\n",
      "Maruti Alto LXi                            47\n",
      "Maruti Alto LX                             35\n",
      "Hyundai EON Era Plus                       35\n",
      "                                           ..\n",
      "Hyundai Verna Transform CRDi VGT SX ABS     1\n",
      "Maruti S-Presso VXI Plus                    1\n",
      "Toyota Etios Liva 1.2 VX                    1\n",
      "Toyota Yaris G                              1\n",
      "Hyundai i20 Magna 1.4 CRDi                  1\n",
      "Name: count, Length: 1491, dtype: int64\n",
      "\n",
      "Maximum km driven for each owner type:\n",
      "owner\n",
      "First Owner             806599\n",
      "Fourth & Above Owner    245244\n",
      "Second Owner            350000\n",
      "Test Drive Car           24585\n",
      "Third Owner             400000\n",
      "Name: km_driven, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'car_details.csv' file and create a pandas dataframe from this file\n",
    "car_details_df = pd.read_csv('./car_details.csv')\n",
    "\n",
    "# Find the maximum price for each of the car brand\n",
    "max_price_per_brand = car_details_df.groupby('name')['selling_price'].max()\n",
    "\n",
    "# Find the average price for each of the fuel types\n",
    "avg_price_per_fuel_type = car_details_df.groupby('fuel')['selling_price'].mean()\n",
    "\n",
    "# Find the average km_driven for each of the seller_types\n",
    "avg_km_driven_per_seller_type = car_details_df.groupby('seller_type')['km_driven'].mean()\n",
    "\n",
    "# Find the count of each of the car names\n",
    "car_name_counts = car_details_df['name'].value_counts()\n",
    "\n",
    "# Find the maximum km_driven for each of the owner types\n",
    "max_km_driven_per_owner_type = car_details_df.groupby('owner')['km_driven'].max()\n",
    "\n",
    "# Print the results\n",
    "print(\"Maximum price for each car brand:\")\n",
    "print(max_price_per_brand)\n",
    "print(\"\\nAverage price for each fuel type:\")\n",
    "print(avg_price_per_fuel_type)\n",
    "print(\"\\nAverage km driven for each seller type:\")\n",
    "print(avg_km_driven_per_seller_type)\n",
    "print(\"\\nCount of each car name:\")\n",
    "print(car_name_counts)\n",
    "print(\"\\nMaximum km driven for each owner type:\")\n",
    "print(max_km_driven_per_owner_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a0b50",
   "metadata": {},
   "source": [
    "####  Concatenating DataFrames\n",
    "<li>pandas.concat() function does all the heavy lifting of performing concatenation operations along with an axis</li>\n",
    "<li>If we want to join two individual dataframes and create a combined dataframe out of it, we can use concatenation operation for doing so.</li>\n",
    "<li>We can use concatenation operation along the rows(axis=0) as well as along the columns(axis = 1)</li>\n",
    "\n",
    "**syntax**\n",
    "\n",
    "<code>\n",
    "    pd.concat([df1,df2], axis, keys, ignore_index)\n",
    "</code>\n",
    "\n",
    "<li>df1 and df2 (required) are two dataframes which we want to merge.</li>\n",
    "<li>axis: axis to concatenate along, (possible values; 0(along the rows) and 1 (along the cols) default = 0 (along the rows).</li>\n",
    "<li>keys: sequence to add an identifier to the result indexes; default = None</li>\n",
    "<li>ignore_index: if True, do not use the index values along the concatenation axis; default = False</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bd33a",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes along the rows\n",
    "![](images/concat_rows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e0379",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames along columns\n",
    "![](images/concat_cols.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f1421",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "<li>Pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL.</li>\n",
    "<li>Pandas provides a single function, merge, as the entry point for all standard database join operations between DataFrame objects.</li>\n",
    "<li>The <b>merge()</b> method updates the content of two DataFrame by merging them together, using the specified method(s).</li>\n",
    "<li>We can use the parameters to control which values to keep and which to replace during merge operation.</li>\n",
    "<li>We can specify any type of join we want by using how parameter in merge method.</li>\n",
    "<li>There are four types of join operations. They are :</li>\n",
    "<ol>\n",
    "    <b><li>Inner join</li></b>\n",
    "    <b><li>Left join</li></b>\n",
    "    <b><li>Right join</li></b>\n",
    "    <b><li>Outer join</li></b>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ece457",
   "metadata": {},
   "source": [
    "#### 1. Inner Join\n",
    "![](images/inner_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b8516",
   "metadata": {},
   "source": [
    "#### 2. Left Join\n",
    "\n",
    "![](images/left_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1879a7d",
   "metadata": {},
   "source": [
    "#### 3. Right Join\n",
    "\n",
    "![](images/right_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11437251",
   "metadata": {},
   "source": [
    "#### 4. Outer Join\n",
    "\n",
    "![](images/outer_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9ae1b",
   "metadata": {},
   "source": [
    "#### Crosstab \n",
    "\n",
    "<li>Cross tabulation is used to quantitatively analyze the relationship between multiple variables.</li>\n",
    "<li>Cross tabulations  also referred to as contingency tables or crosstabs.</li>\n",
    "<li>They group variables together and enable researchers to understand the correlation between different variables.<li>\n",
    "<li>When we are doing multivariate analysis then we often came across crosstab() methods in pandas.</li>\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "<code>\n",
    "    pd.crosstab(index, columns, values, margins, margin_names, normalize,aggfunc, dropna)\n",
    "</code>\n",
    "<ol>\n",
    "    <li>index : array-like, Series, or list of arrays/Series, Values to group by in the rows.</li>\n",
    "    <li>columns : array-like, Series, or list of arrays/Series, Values to group by in the columns.</li>\n",
    "    <li>values : array-like, optional, array of values to aggregate according to the factors. Requires `aggfunc` be specified.     </li>\n",
    "    <li>aggfunc : function, optional, If specified, requires `values` be specified as well.</li>\n",
    "    <li>margins : bool, default False, Add row/column margins (subtotals).</li>\n",
    "    <li>margins_name : str, default All, Name of the row/column that will contain the totals when margins is True.</li>\n",
    "    <li>dropna : bool, default True, Do not include columns whose entries are all NaN.</li>\n",
    "    <li>normalize: </li>\n",
    "    <ol>\n",
    "        <li>If passed all or True, will normalize over all values.</li>\n",
    "        <li>If passed index will normalize over each row.</li>\n",
    "        <li>If passed columns will normalize over each column.</li>\n",
    "        <li>If margins is True, will also normalize margin values.</li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278baf6a",
   "metadata": {},
   "source": [
    "#### Pivot\n",
    "<li>pivot() method produces pivot table based on 3 columns of the DataFrame. Uses unique values from index / columns and fills with values.</li>\n",
    "\n",
    "    \n",
    "**syntax**\n",
    "<code>\n",
    "pd.pivot(index, columns, values)\n",
    "</code>\n",
    "    \n",
    "<b>Parameters:</b>\n",
    "<ol>\n",
    "    <li>index[ndarray] : Labels to use to make new frames index</li>\n",
    "    <li>columns[ndarray] : Labels to use to make new frames columns</li>\n",
    "    <li>values[ndarray] : Values to use for populating new frames values</li>\n",
    "</ol>\n",
    "\n",
    "**Returns: Reshaped DataFrame**\n",
    "\n",
    "**Exception: ValueError raised if there are any duplicates.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
